{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W_4_Bagging_and_RandomForest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLmXOqA4xhq"
      },
      "source": [
        "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits). \n",
        "\n",
        "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.model_selection с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
        "\n",
        "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадет в диапазон, заданный для правильных ответов - в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
        "\n",
        "Если вам захочется ускорить вычисление cross_val_score - можете попробовать использовать параметр n_jobs, но будьте осторожны: в одной из старых версий sklearn была ошибка, которая приводила к неверному результату работы cross_val_score при задании n_jobs отличным от 1. Сейчас такой проблемы возникнуть не должно, но проверить, что все в порядке, не будет лишним."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsY8tzsf5vof"
      },
      "source": [
        "from sklearn import datasets, tree, ensemble\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "from math import sqrt\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul3sIe876OpH"
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "X = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqVn9xQL674c"
      },
      "source": [
        "def write_answer(cross_val_score, file_name):\n",
        "    with open(file_name, \"w\") as fout:\n",
        "        fout.write(str(cross_val_score))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iGHIri40U8"
      },
      "source": [
        "#Задание 1.\n",
        "\n",
        "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эта величина и будет ответом в пункте 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36MIDo-F78aN",
        "outputId": "827b5c73-2b31-42b1-f26a-332f78e0ea1b"
      },
      "source": [
        "classifier = tree.DecisionTreeClassifier()\n",
        "x_val_score = cross_val_score(classifier, X, y, cv=10).mean()\n",
        "write_answer(x_val_score, 'answer_1.txt')\n",
        "print(x_val_score)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8285940409683427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FLKOZ5h46VF"
      },
      "source": [
        "#Задание 2.\n",
        "\n",
        "Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd7coNYl5F25"
      },
      "source": [
        "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7lwax3Z8bDn",
        "outputId": "2e1d44fe-bc08-42fa-99a9-7fd06ddb481f"
      },
      "source": [
        "bagging_classifier = ensemble.BaggingClassifier(classifier, n_estimators=100)\n",
        "x_val_score = cross_val_score(bagging_classifier, X, y, cv=10).mean()\n",
        "write_answer(x_val_score, 'answer_2.txt')\n",
        "print(x_val_score)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9209497206703909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAdnByhQ5Are"
      },
      "source": [
        "#Задание 3\n",
        "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на\n",
        "$\\sqrt{d}$ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLwQXE6A9bGT",
        "outputId": "c137d999-c6c3-434f-cf84-b0f2d1924a9d"
      },
      "source": [
        "train_feature_number = int(sqrt(X.shape[1]))\n",
        "bagging_classifier = ensemble.BaggingClassifier(classifier, n_estimators=100, max_features=train_feature_number)\n",
        "x_val_score = cross_val_score(bagging_classifier, X, y, cv=10).mean()\n",
        "write_answer(x_val_score, 'answer_3.txt')\n",
        "print(x_val_score)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9265487274984482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvcjiZlJ5BFB"
      },
      "source": [
        "#Задание 4\n",
        "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же $\\sqrt{d}$ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0EypTG5-Cjj",
        "outputId": "d0a84451-c8fb-4538-c6cd-3aacff5d8a8f"
      },
      "source": [
        "stohastic_classifier = tree.DecisionTreeClassifier(max_features=train_feature_number)\n",
        "bagging_classifier = ensemble.BaggingClassifier(stohastic_classifier, n_estimators=100)\n",
        "x_val_score_4 = cross_val_score(bagging_classifier, X, y, cv=10).mean()\n",
        "write_answer(x_val_score_4, 'answer_4.txt')\n",
        "print(x_val_score_4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9493482309124767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e41TWGqx5DAJ"
      },
      "source": [
        "#Задание 5\n",
        "Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH_kTy2Y-aP3",
        "outputId": "462e284f-19f9-4ce5-9c02-3f705f01d65e"
      },
      "source": [
        "random_forest = ensemble.RandomForestClassifier(random_state=train_feature_number, n_estimators=100)\n",
        "x_val_score_5 = cross_val_score(random_forest, X, y, cv=10).mean()\n",
        "print(x_val_score_5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9487988826815641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qik0-sAg-aoF"
      },
      "source": [
        "На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)\n",
        "\n",
        "1. Случайный лес сильно переобучается с ростом количества деревьев\n",
        "\n",
        "2. При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
        "\n",
        "3. С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
        "\n",
        "4. При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
        "\n",
        "5. При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
        "\n",
        "6. При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
        "\n",
        "7. При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUeBx3rp-bQr"
      },
      "source": [
        "answers = '2 3 4 7'\n",
        "write_answer(answers, 'answer5.txt')"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}